{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-12 14:02:22 [importing.py:53] Triton module has been replaced with a placeholder.\n",
      "INFO 05-12 14:02:22 [__init__.py:239] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import copy\n",
    "import math\n",
    "import re\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from trl import GRPOConfig, GRPOTrainer\n",
    "from torch.utils.data import DataLoader, Dataset as TorchDataset, IterableDataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS = {\n",
    "    \"ALPHA\": 0.5,\n",
    "    \"DIFFICULTY_FACTOR\": 0.5,\n",
    "    \"VARIANCE_FACTOR\": 0.5,\n",
    "    \"MIN_WEIGHT\": 0.01,\n",
    "    \"TRAIN_BATCH_SIZE\": 4,\n",
    "    \"VALID_BATCH_SIZE\": 2,\n",
    "    \"MAX_STEPS\": 16384,\n",
    "    \"STEPS_PER_UPDATE\": 1,\n",
    "    \"STEPS_PER_EVAL\": 10,\n",
    "    \"NUM_GENERATIONS\": 4,\n",
    "    \"MAX_COMPLETION_LENGTH\": 1024,\n",
    "    \"LEARNING_RATE\": 2e-4,\n",
    "    \"BETA\": 0.04,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a93b696850ba4b0493606806d2ac2a15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpus = torch.cuda.device_count()\n",
    "\n",
    "model_dir = \"Qwen/Qwen3-4B-Base\"\n",
    "compute_dtype = torch.float16\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_dir,\n",
    "    trust_remote_code=True,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "        r=32,\n",
    "        lora_alpha=32,\n",
    "        target_modules=[\n",
    "            'q_proj',\n",
    "            'k_proj',\n",
    "            'v_proj',\n",
    "            'dense'\n",
    "        ],\n",
    "        bias=\"none\",\n",
    "        lora_dropout=0.05,\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "    )\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir, use_fast=True, padding_side=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(question):\n",
    "    chat = [\n",
    "        {\"role\": \"system\", \"content\": \"A conversation between User and Assistant. The user asks a question, and the Assistant solves it. The assistant first thinks about the reasoning process in the mind and then provides the user with the answer. The reasoning process and answer are enclosed within <think> </think> and <answer> </answer> tags, respectively, i.e., <think> reasoning process here </think> <answer> answer here </answer>\"},\n",
    "        {\"role\": \"user\", \"content\": question + ' Return final answer within \\\\boxed{}.'}\n",
    "    ]\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        conversation=chat,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem</th>\n",
       "      <th>answer</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>In an equation of the form $k = ax^2 + bx + c$...</td>\n",
       "      <td>-150</td>\n",
       "      <td>&lt;|im_start|&gt;system\\nA conversation between Use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1534</th>\n",
       "      <td>In the land of Ink, the money system is unique...</td>\n",
       "      <td>6</td>\n",
       "      <td>&lt;|im_start|&gt;system\\nA conversation between Use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>A street has 50 houses on each side, for a tot...</td>\n",
       "      <td>245</td>\n",
       "      <td>&lt;|im_start|&gt;system\\nA conversation between Use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>The largest term in the binomial expansion of ...</td>\n",
       "      <td>1024</td>\n",
       "      <td>&lt;|im_start|&gt;system\\nA conversation between Use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>Let $\\alpha$ and $\\beta$ be angles for which\\n...</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;|im_start|&gt;system\\nA conversation between Use...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                problem answer  \\\n",
       "239   In an equation of the form $k = ax^2 + bx + c$...   -150   \n",
       "1534  In the land of Ink, the money system is unique...      6   \n",
       "1103  A street has 50 houses on each side, for a tot...    245   \n",
       "555   The largest term in the binomial expansion of ...   1024   \n",
       "888   Let $\\alpha$ and $\\beta$ be angles for which\\n...      8   \n",
       "\n",
       "                                                 prompt  \n",
       "239   <|im_start|>system\\nA conversation between Use...  \n",
       "1534  <|im_start|>system\\nA conversation between Use...  \n",
       "1103  <|im_start|>system\\nA conversation between Use...  \n",
       "555   <|im_start|>system\\nA conversation between Use...  \n",
       "888   <|im_start|>system\\nA conversation between Use...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = \"AIME_IMO_MATH.csv\"\n",
    "data = pd.read_csv(dataset_path)\n",
    "data['prompt'] = data['problem'].apply(create_prompt)\n",
    "train_df, test_df = train_test_split(data, test_size=0.1, random_state=42, shuffle=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveDataset(IterableDataset):\n",
    "    def __init__(self, prompts, num_generations=4, alpha=0.5, difficulty_factor=0.5, variance_factor=0.5, min_weight=0.01):\n",
    "        self.alpha = alpha\n",
    "        self.difficulty_factor = difficulty_factor\n",
    "        self.variance_factor = variance_factor\n",
    "        self.num_generations = num_generations\n",
    "        self.min_weight = min_weight\n",
    "        \n",
    "        self.data = []\n",
    "        for _, prompt in prompts.iterrows():\n",
    "            self.data.append({\n",
    "                \"problem\": prompt[\"problem\"],\n",
    "                \"answer\": str(prompt[\"answer\"]),\n",
    "                \"prompt\": prompt[\"prompt\"]\n",
    "            })\n",
    "        \n",
    "        n = len(self.data)\n",
    "        \n",
    "        self._mean_rewards = torch.zeros(n)\n",
    "        self._var_rewards = torch.zeros(n)\n",
    "        self._weights = torch.ones(n)\n",
    "        self._reward_counts = torch.zeros(n)\n",
    "        self._update_probabilities()\n",
    "    \n",
    "    def _update_probabilities(self):\n",
    "        weights = self._weights + self.min_weight\n",
    "        self._probabilities = weights / weights.sum()\n",
    "    \n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            idx = torch.multinomial(self._probabilities, 1, replacement=True).item()\n",
    "            sample = {\n",
    "                \"index\": idx,\n",
    "                \"problem\": self.data[idx][\"problem\"],\n",
    "                \"answer\": self.data[idx][\"answer\"],\n",
    "                \"prompt\": self.data[idx][\"prompt\"],\n",
    "                \"current_weight\": self._weights[idx].item()\n",
    "            }\n",
    "            for _ in range(self.num_generations):\n",
    "                yield sample\n",
    "            \n",
    "    \n",
    "    def update_weights(self, reward_records):\n",
    "        alpha = self.alpha\n",
    "        for idx, rewards in reward_records:\n",
    "            if not rewards:\n",
    "                continue\n",
    "            r_tensor = torch.tensor(rewards, dtype=torch.float32)\n",
    "            new_mean = r_tensor.mean().item()\n",
    "            new_var = r_tensor.var().item()\n",
    "            \n",
    "            self._mean_rewards[idx] = (1 - alpha) * self._mean_rewards[idx] + alpha * new_mean\n",
    "            self._var_rewards[idx] = (1 - alpha) * self._var_rewards[idx] + alpha * new_var\n",
    "            self._reward_counts[idx] += len(rewards)\n",
    "            \n",
    "            difficulty = 1 - self._mean_rewards[idx]\n",
    "            uncertainty = torch.sqrt(self._var_rewards[idx])\n",
    "            self._weights[idx] = self.difficulty_factor * difficulty + self.variance_factor * uncertainty\n",
    "        \n",
    "        self._update_probabilities()\n",
    "    \n",
    "    def get_statistics(self):\n",
    "        weights_np = self._weights.numpy()\n",
    "        means_np = self._mean_rewards.numpy()\n",
    "        \n",
    "        return {\n",
    "            \"weight_distribution\": {\n",
    "                \"min\": float(weights_np.min()),\n",
    "                \"max\": float(weights_np.max()),\n",
    "                \"mean\": float(weights_np.mean()),\n",
    "                \"std\": float(weights_np.std())\n",
    "            },\n",
    "            \"performance_distribution\": {\n",
    "                \"mean_reward\": float(means_np.mean()),\n",
    "                \"hardest_problems\": means_np.argsort()[:5].tolist(),\n",
    "                \"most_uncertain\": self._var_rewards.argsort(descending=True)[:5].tolist()\n",
    "            },\n",
    "            \"sampling_distribution\": {\n",
    "                \"entropy\": float(-(self._probabilities * torch.log(self._probabilities + 1e-8)).sum()),\n",
    "                \"max_probability\": float(self._probabilities.max()),\n",
    "                \"effective_dataset_size\": float(1.0 / (self._probabilities ** 2).sum())\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def get_item_metadata(self, idx):\n",
    "        return {\n",
    "            \"mean_reward\": self._mean_rewards[idx].item(),\n",
    "            \"var_reward\": self._var_rewards[idx].item(),\n",
    "            \"weight\": self._weights[idx].item(),\n",
    "            \"reward_count\": self._reward_counts[idx].item(),\n",
    "            \"sampling_probability\": self._probabilities[idx].item()\n",
    "        }\n",
    "    \n",
    "    def reset_weights(self):\n",
    "        self._mean_rewards.fill_(0.0)\n",
    "        self._var_rewards.fill_(0.0)\n",
    "        self._weights.fill_(1.0)\n",
    "        self._reward_counts.fill_(0.0)\n",
    "        self._update_probabilities()\n",
    "\n",
    "\n",
    "class ValidationDataset(TorchDataset):\n",
    "    def __init__(self, validation_df):\n",
    "        self.data = []\n",
    "        for _, row in validation_df.iterrows():\n",
    "            self.data.append({\n",
    "                \"problem\": row[\"problem\"],\n",
    "                \"answer\": str(row[\"answer\"]),\n",
    "                \"prompt\": row[\"prompt\"]\n",
    "            })\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"index\": idx,\n",
    "            \"problem\": self.data[idx][\"problem\"],\n",
    "            \"answer\": self.data[idx][\"answer\"],\n",
    "            \"prompt\": self.data[idx][\"prompt\"]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = AdaptiveDataset(train_df, num_generations=PARAMS[\"NUM_GENERATIONS\"], alpha=PARAMS[\"ALPHA\"], difficulty_factor=PARAMS[\"DIFFICULTY_FACTOR\"], \n",
    "                                variance_factor=PARAMS[\"VARIANCE_FACTOR\"], \n",
    "                                min_weight=PARAMS[\"MIN_WEIGHT\"])\n",
    "\n",
    "valid_dataset = ValidationDataset(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_boxed_text(text):\n",
    "    pattern = r\"\\\\boxed\\{(.*?)\\}\"\n",
    "    matches = re.findall(pattern, text)\n",
    "    if not matches:\n",
    "        return \"\"\n",
    "    for match in reversed(matches):\n",
    "        if match.strip():\n",
    "            return match.strip()\n",
    "    return \"\"\n",
    "\n",
    "def accuracy_reward_func(completions, answer, index, **kwargs):\n",
    "    rewards = []\n",
    "    for comp, val in zip(completions, answer):\n",
    "        extracted = extract_boxed_text(comp)\n",
    "        rewards.append(1.0 if str(extracted) == str(val) else 0.0)\n",
    "\n",
    "    rewards_buffer = []\n",
    "    num_prompts = PARAMS[\"TRAIN_BATCH_SIZE\"] // PARAMS[\"NUM_GENERATIONS\"]\n",
    "    for i in range(num_prompts):\n",
    "        question_idx = index[i * PARAMS[\"NUM_GENERATIONS\"]]\n",
    "        rewards_distr = []\n",
    "        for j in range(PARAMS[\"NUM_GENERATIONS\"]):\n",
    "            idx = i * PARAMS[\"NUM_GENERATIONS\"] + j\n",
    "            rewards_distr.append(rewards[idx])\n",
    "        rewards_buffer.append((question_idx, rewards_distr))\n",
    "    train_dataset.update_weights(rewards_buffer)\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "from trl import GRPOConfig, GRPOTrainer\n",
    "from transformers import PrinterCallback\n",
    "\n",
    "\n",
    "training_args = GRPOConfig(\n",
    "    learning_rate=PARAMS[\"LEARNING_RATE\"],\n",
    "    per_device_train_batch_size=PARAMS[\"TRAIN_BATCH_SIZE\"],\n",
    "    gradient_accumulation_steps=1,\n",
    "    max_steps=PARAMS[\"MAX_STEPS\"],\n",
    "    max_completion_length=PARAMS[\"MAX_COMPLETION_LENGTH\"],\n",
    "    num_generations=PARAMS[\"NUM_GENERATIONS\"],\n",
    "    beta=PARAMS[\"BETA\"],\n",
    "    logging_steps=1, \n",
    "    accelerator_config={\n",
    "            \"dispatch_batches\": False\n",
    "    },\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = GRPOTrainer(\n",
    "        model=model,\n",
    "        reward_funcs=accuracy_reward_func,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        peft_config=lora_config,\n",
    "        callbacks=[PrinterCallback()]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='16384' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [    2/16384 : < :, Epoch 0.00/9223372036854775807]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 0.0002, 'num_tokens': 4780.0, 'completions/mean_length': 1024.0, 'completions/min_length': 1024.0, 'completions/max_length': 1024.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/accuracy_reward_func/mean': 0.0, 'rewards/accuracy_reward_func/std': 0.0, 'reward': 0.0, 'reward_std': 0.0, 'kl': 0.0, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 6.103515625e-05}\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaL4",
   "dataSources": [
    {
     "databundleVersionId": 11802066,
     "isSourceIdPinned": false,
     "sourceId": 91496,
     "sourceType": "competition"
    },
    {
     "datasetId": 6487234,
     "sourceId": 10476716,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 220844327,
     "sourceType": "kernelVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 322000,
     "modelInstanceId": 301515,
     "sourceId": 363135,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
